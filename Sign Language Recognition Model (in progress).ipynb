{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "_hdo0Onkh9yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #to play with the directories\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "oc4MRj2Jg5KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset normalization"
      ],
      "metadata": {
        "id": "f4Qd9LeRiLSI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x_LFtYSRgebg"
      },
      "outputs": [],
      "source": [
        "def preprocess_img(image,label,image_size=224):\n",
        "  return tf.cast(image/255. ,tf.float32),label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching our Dataset"
      ],
      "metadata": {
        "id": "nN3HVmfDkIHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.map(map_func=preprocess_img,num_parallel_calls=tf.data.AUTOTUNE) # use preprocess_img function for all of the train_data, and autotune is used to tell gpu to use all of the computational power\n",
        "train_data=train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_data = test_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "test_data = test_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE).cache()"
      ],
      "metadata": {
        "id": "VI9t6LuKghl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction Model without fine tuning(all layers are frezed)"
      ],
      "metadata": {
        "id": "P9QFtfJBrfTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\", dtype=tf.float16)\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(len(labels))(x) \n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x) \n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dsPyZsqopjMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fiting the training data on the above feature extraction model."
      ],
      "metadata": {
        "id": "rLJMkgYlroVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_on_model_with_freezed_layer = model.fit(train_data, epochs=3,steps_per_epoch=len(train_data),validation_data=test_data,validation_steps=int(0.15 * len(test_data)),)"
      ],
      "metadata": {
        "id": "kmRWJzfmpi8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating our Model on the feature extraction model without fine tuning\n"
      ],
      "metadata": {
        "id": "AS28NuxksAle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "zAGRQmA9r_3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfreezing layers of the EfficientNetB0"
      ],
      "metadata": {
        "id": "g55fRDi1sHuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  layer.trainable=True"
      ],
      "metadata": {
        "id": "EtgV3wP8sThF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now compiling the model with fine tuning i.e. unfreezed layer"
      ],
      "metadata": {
        "id": "tyg8f15ssc1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7f6qkogBsXas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating our Model on the feature extraction model with fine tuning"
      ],
      "metadata": {
        "id": "RmMwUKT7s6f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_from_fine_tuned_model = model.fit(train_data, epochs=100,steps_per_epoch=len(train_data),validation_data=test_data,validation_steps=int(0.15 * len(test_data)),)"
      ],
      "metadata": {
        "id": "lKFtDSDIslCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}